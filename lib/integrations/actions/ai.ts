import { createIntegration } from "../utils";
import type { Integration } from "../types";

export const aiIntegration: Integration = createIntegration({
  id: "ai",
  name: "AI",
  category: "action",
  description: "LLM, image generation, text-to-speech, and speech-to-text",
  icon: "brain",
  version: "1.0.0",

  schema: {
    fields: [
      {
        key: "ai_mode",
        type: "select",
        label: "AI Mode",
        required: true,
        options: [
          { label: "Text Generation (LLM)", value: "llm" },
          { label: "Image Generation", value: "image" },
          { label: "Text to Speech", value: "tts" },
          { label: "Speech to Text", value: "stt" },
        ],
      },
      {
        key: "model",
        type: "select",
        label: "AI Model",
        required: true,
        options: [
          { label: "GPT-4", value: "gpt-4" },
          { label: "GPT-3.5 Turbo", value: "gpt-3.5-turbo" },
          { label: "Claude-3 Opus", value: "claude-3-opus" },
          { label: "Claude-3 Sonnet", value: "claude-3-sonnet" },
          { label: "DALL-E 3", value: "dall-e-3" },
          { label: "Midjourney", value: "midjourney" },
          { label: "Stable Diffusion", value: "stable-diffusion" },
          { label: "Whisper", value: "whisper" },
          { label: "ElevenLabs", value: "elevenlabs" },
        ],
      },
      {
        key: "prompt",
        type: "textarea",
        label: "Prompt/Input",
        placeholder:
          "Enter your prompt, text, or describe what you want to generate...",
        required: true,
        supportExpressions: true,
      },
      {
        key: "max_tokens",
        type: "number",
        label: "Max Tokens (LLM only)",
        placeholder: "1000",
        required: false,
      },
      {
        key: "temperature",
        type: "number",
        label: "Temperature/Creativity",
        placeholder: "0.7",
        required: false,
      },
      {
        key: "image_size",
        type: "select",
        label: "Image Size (Image generation only)",
        required: false,
        options: [
          { label: "1024x1024", value: "1024x1024" },
          { label: "1792x1024", value: "1792x1024" },
          { label: "1024x1792", value: "1024x1792" },
        ],
      },
      {
        key: "voice_id",
        type: "select",
        label: "Voice ID (TTS only)",
        required: false,
        options: [
          { label: "Rachel (Female)", value: "rachel" },
          { label: "Domingo (Male)", value: "domingo" },
          { label: "Bella (Female)", value: "bella" },
          { label: "Antoni (Male)", value: "antoni" },
        ],
      },
      {
        key: "language",
        type: "select",
        label: "Language (STT only)",
        required: false,
        options: [
          { label: "English", value: "en" },
          { label: "Spanish", value: "es" },
          { label: "French", value: "fr" },
          { label: "German", value: "de" },
          { label: "Japanese", value: "ja" },
        ],
      },
    ],
    required: ["ai_mode", "model", "prompt"],
  },

  executor: {
    async execute(config: Record<string, unknown>) {
      const {
        ai_mode,
        model,
        prompt,
        max_tokens,
        temperature,
        image_size,
        voice_id,
        language,
      } = config;

      // Simulate API call delay
      await new Promise((resolve) => setTimeout(resolve, 800));

      const timestamp = new Date().toISOString();
      const executionId = `ai_${Date.now()}_${Math.random()
        .toString(36)
        .substr(2, 9)}`;

      // Mock responses based on AI mode
      let response: Record<string, unknown> = {};

      switch (ai_mode) {
        case "llm":
          response = {
            text: `Here's a response to your prompt: "${prompt}"\n\nThis is a mock LLM response generated by ${model}. In a real implementation, this would be the actual AI-generated text based on your prompt. The response would be tailored to your specific request and would demonstrate the AI's understanding and capabilities.`,
            tokens_used: Math.floor(Math.random() * 500) + 100,
            finish_reason: "stop",
            model_used: model,
          };
          break;

        case "image":
          response = {
            image_url: `https://example.com/generated-images/${executionId}.png`,
            image_id: executionId,
            prompt: prompt,
            size: image_size || "1024x1024",
            model_used: model,
            generation_time: "2.3s",
          };
          break;

        case "tts":
          response = {
            audio_url: `https://example.com/generated-audio/${executionId}.mp3`,
            audio_id: executionId,
            text: prompt,
            voice_used: voice_id || "rachel",
            duration: "3.2s",
            sample_rate: "44100Hz",
          };
          break;

        case "stt":
          response = {
            text: "This is a mock transcription of the provided audio. In a real implementation, this would be the actual transcribed text from the audio file.",
            confidence: 0.95,
            language: language || "en",
            duration: "5.1s",
            words: 12,
          };
          break;
      }

      return {
        success: true,
        data: {
          ...response,
          execution_id: executionId,
          timestamp,
          ai_mode,
          model,
          prompt,
          config: {
            max_tokens,
            temperature,
            image_size,
            voice_id,
            language,
          },
        },
        metadata: {
          nodeType: "action",
          subtype: "ai",
          aiMode: ai_mode,
          model: model,
        },
      };
    },

    validate(config: Record<string, unknown>) {
      const errors: Record<string, string> = {};

      if (!config.ai_mode) {
        errors.ai_mode = "AI mode is required";
      }

      if (!config.model) {
        errors.model = "Model is required";
      }

      if (!config.prompt) {
        errors.prompt = "Prompt is required";
      }

      // Validate model compatibility with AI mode
      if (config.ai_mode && config.model) {
        const aiMode = config.ai_mode as string;
        const model = config.model as string;

        const validModels = {
          llm: ["gpt-4", "gpt-3.5-turbo", "claude-3-opus", "claude-3-sonnet"],
          image: ["dall-e-3", "midjourney", "stable-diffusion"],
          tts: ["elevenlabs"],
          stt: ["whisper"],
        };

        if (
          validModels[aiMode as keyof typeof validModels] &&
          !validModels[aiMode as keyof typeof validModels].includes(model)
        ) {
          errors.model = `Model ${model} is not compatible with ${aiMode} mode`;
        }
      }

      return {
        valid: Object.keys(errors).length === 0,
        errors,
      };
    },
  },
});
